{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 2em;\">BIG DATA</span>\n",
    "\n",
    "<span style=\"color:#f00; font-family: 'Bebas Neue'; font-size: 1.5em;\">Unit 4: Introduction to Natural Langauge Processing </span>\n",
    "\n",
    "<span style=\"color:#300; font-family: 'Bebas Neue'; font-size: 1.5em;\">4.1 Basics in Python</span>\n",
    "<h4 style=\"color:darkblue\"> Universidad de Deusto</h4>\n",
    "\n",
    "<span style=\"color:#300; font-family: 'Bebas Neue'; font-size: 1em;\">m.varo@deusto.es</span>\n",
    "\n",
    "<img src=\"https://www.ciberseguridad.eus/sites/default/files/company_logos/deusto-logo.png\" alt=\"drawing\" style=\"width:200px;\"/>\n",
    "\n",
    "<h5 style=\"color:black\">  11 March 2025 - Donostia </h5>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of examples in this article are borrowed from the book written by **Bird et al. (2009)**. Here I tried to implement the examples from the book with spark as much as possible.\n",
    "\n",
    "Refer to the book for more details: Bird, Steven, Ewan Klein, and Edward Loper. Natural language processing with Python: analyzing text with the natural language toolkit. \" O'Reilly Media, Inc.\", 2009.\n",
    "\n",
    "## Basic terminology\n",
    "\n",
    "* **text**: a sequence of words and punctuation.\n",
    "* **frequency distribution**: the frequency of words in a text object.\n",
    "* **collocation**: a **sequence of words** that occur together unusually often.\n",
    "* **bigrams**: word pairs. High frequent bigrams are collocations.\n",
    "* **corpus**: a large body of text\n",
    "* **wordnet**: a lexical database in which english words are grouped into sets of synonyms (**also called synsets**).\n",
    "* **text normalization**: the process of transforming text into a single canonical form, e.g., converting text to lowercase, removing punctuations and so on.\n",
    "* **Lemmatization**: the process of grouping variant forms of the same word so that they can be analyzed as a single item.\n",
    "* **Stemming**: the process of reducing inflected words to their **word stem**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing NLTK and Setting up Python Environment**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that NLTK also requires some additional data to be downloaded before it can be used effectively. \n",
    "This data includes pre-trained models, corpora, and other resources that NLTK uses to perform various NLP tasks. \n",
    "To download this data, run the following command in terminal or your Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Text**\n",
    "\n",
    "Text preprocessing is a crucial step in performing sentiment analysis, as it helps to clean and normalize the text data, making it easier to analyze. The preprocessing step involves a series of techniques that help transform raw text data into a form you can use for analysis. Some common text preprocessing techniques include tokenization, stop word removal, stemming, and lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.datacamp.com/legacy/v1718119424/image_7d0097c66c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization**\n",
    "\n",
    "Tokenization is the process of breaking text into smaller units, such as words or sentences. It helps analyze and manipulate text data. This is an essential step in analyzing text data as it helps to separate individual words from the raw text, making it easier to analyze and understand. Tokenization is typically performed using NLTK's built-in word_tokenize function, which can split the text into individual words and punctuation marks.\n",
    "\n",
    "- **Word Tokenization**: Splitting text into individual words.  \n",
    "  *Example:* `\"Sentiment analysis is fun!\"` â†’ `[\"Sentiment\", \"analysis\", \"is\", \"fun\", \"!\"]`  \n",
    "- **Sentence Tokenization**: Splitting text into individual sentences.  \n",
    "  *Example:* `\"I love NLP. It's amazing!\"` â†’ `[\"I love NLP.\", \"It's amazing!\"]`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:\n",
      "['Tokenization is the process of breaking text into smaller units.', 'These units can be words or sentences!']\n",
      "\n",
      "Word Tokenization:\n",
      "['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'text', 'into', 'smaller', 'units', '.', 'These', 'units', 'can', 'be', 'words', 'or', 'sentences', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Example text\n",
    "text = \"Tokenization is the process of breaking text into smaller units. These units can be words or sentences!\"\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\")\n",
    "print(sentences)\n",
    "\n",
    "# Word Tokenization\n",
    "words = word_tokenize(text)\n",
    "print(\"\\nWord Tokenization:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop words**\n",
    "\n",
    "Stop word removal is a crucial text preprocessing step in sentiment analysis that involves removing common and irrelevant words that are unlikely to convey much sentiment. Stop words are words that are very common in a language and do not carry much meaning, such as \"and,\" \"the,\" \"of,\" and \"it.\" These words can cause noise and skew the analysis if they are not removed.\n",
    "\n",
    "By removing stop words, the remaining words in the text are more likely to indicate the sentiment being expressed. This can help to improve the accuracy of the sentiment analysis. \n",
    "\n",
    "NLTK provides a built-in list of stop words for several languages, which can be used to filter out these words from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Words (without stop words):\n",
      "['Tokenization', 'process', 'breaking', 'text', 'smaller', 'units', '.', 'units', 'words', 'sentences', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Removing Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"\\nFiltered Words (without stop words):\")\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming and Lemmatization**\n",
    "\n",
    "Stemming and lemmatization are techniques used to reduce words to their root forms. Stemming involves removing the suffixes from words, such as \"ing\" or \"ed,\" to reduce them to their base form. For example, the word \"jumping\" would be stemmed to \"jump.\"\n",
    "\n",
    "Lemmatization, however, involves reducing words to their base form based on their part of speech. For example, the word \"jumped\" would be lemmatized to \"jump,\" but the word \"jumping\" would be lemmatized to \"jumping\" since it is a present participle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mvallevaro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mvallevaro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download the necessary NLTK resources (only needed once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'process', 'breaking', 'text', 'smaller', 'units', '.', 'units', 'words', 'sentences', '!']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming:\n",
      "['token', 'process', 'break', 'text', 'smaller', 'unit', '.', 'unit', 'word', 'sentenc', '!']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "print(\"\\nStemming:\")\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatization:\n",
      "['Tokenization', 'process', 'breaking', 'text', 'smaller', 'unit', '.', 'unit', 'word', 'sentence', '!']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(\"\\nLemmatization:\")\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- Stemming reduces words to their root form by chopping off suffixes.\n",
    "- Example: \"running\" â†’ \"run\", \"flies\" â†’ \"fli\".\n",
    "- Uses a heuristic approach, which can sometimes produce non-dictionary words.\n",
    "\n",
    "### Lemmatization\n",
    "- Lemmatization returns the base or dictionary form of a word.\n",
    "- Example: \"running\" â†’ \"run\", \"flies\" â†’ \"fly\".\n",
    "- More accurate than stemming, but computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words (BoW) Model**\n",
    "\n",
    "The bag of words model is a technique used in natural language processing (NLP) to represent text data as a set of numerical features. \n",
    "\n",
    "In this model, each document or piece of text is represented as a \"bag\" of words, with each word in the text represented by a separate feature or dimension in the resulting vector. The value of each feature is determined by the number of times the corresponding word appears in the text.\n",
    "\n",
    "The bag of words model is useful in NLP because **it allows us to analyze text data using machine learning algorithms, which typically require numerical input. By representing text data as numerical features, we can train machine learning models to classify text or analyze sentiments.**\n",
    "\n",
    "\n",
    "- The Bag of Words model represents text as a collection of word frequencies.\n",
    "- Each unique word in the dataset is treated as a feature.\n",
    "- Example representation:\n",
    "  - Sentence: \"This is the first document.\"\n",
    "  - Features: {'this', 'is', 'the', 'first', 'document'}\n",
    "  - Vector: [1, 1, 1, 1, 1]\n",
    "- BoW ignores grammar and word order but captures word frequency.\n",
    "\"\"\"\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:893/1*axffCQ9ae0FHXxhuy66FbA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag of Words Model:\n",
      "Feature Names: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "BoW Representation:\n",
      " [[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag of Words Model\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"\\nBag of Words Model:\")\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(\"BoW Representation:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF (Term Frequency - Inverse Document Frequency)**\n",
    "TF-IDF improves BoW by weighting words based on importance:\n",
    "- **Term Frequency (TF)**: Number of times a word appears in a document.\n",
    "- **Inverse Document Frequency (IDF)**: Measures how unique a word is across all documents.\n",
    "- Words that appear in many documents have lower weights, while rare words have higher importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Model\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Representation:\n",
      "    and  document  first  is  one  second  the  third  this\n",
      "0    0         1      1   1    0       0    1      0     1\n",
      "1    0         2      0   1    0       1    1      0     1\n",
      "2    1         0      0   1    1       0    1      1     1\n",
      "3    0         1      1   1    0       0    1      0     1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert BoW to DataFrame\n",
    "bow_df = pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(\"Bag of Words Representation:\\n\", bow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Model\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Representation:\n",
      "         and  document     first        is       one    second       the  \\\n",
      "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
      "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
      "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "\n",
      "      third      this  \n",
      "0  0.000000  0.384085  \n",
      "1  0.000000  0.281089  \n",
      "2  0.511849  0.267104  \n",
      "3  0.000000  0.384085  \n"
     ]
    }
   ],
   "source": [
    "# Convert TF-IDF to DataFrame\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Representation:\\n\", tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of BoW Matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(bow_df, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Bag of Words Representation\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Documents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of TF-IDF Matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(tfidf_df, annot=True, cmap=\"Oranges\", fmt=\".2f\")\n",
    "plt.title(\"TF-IDF Representation\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Documents\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Conclusions from the Bag of Words (BoW) and TF-IDF Graphs**\n",
    "\n",
    " **1. Bag of Words (BoW) Representation**\n",
    "- The BoW model **counts the occurrences of words** in each document without considering their importance.\n",
    "- Words that appear frequently across multiple documents (e.g., *\"document\"*, *\"this\"*, *\"is\"*) have higher values in the matrix.\n",
    "- The BoW representation does not differentiate between important and common words, treating all words equally.\n",
    "\n",
    " **2. TF-IDF Representation**\n",
    "- The TF-IDF model **adjusts word importance** by penalizing common words and highlighting unique words.\n",
    "- Frequently occurring words (e.g., *\"document\"*, *\"this\"*, *\"is\"*) have **lower TF-IDF scores** because they appear in multiple documents, making them less significant.\n",
    "- Words that appear less frequently in the corpus (e.g., *\"second\"*, *\"third\"*, *\"one\"*) receive **higher TF-IDF scores**, emphasizing their importance in individual documents.\n",
    "\n",
    " **Key Differences**\n",
    "| Feature | Bag of Words (BoW) | TF-IDF |\n",
    "|---------|--------------------|--------|\n",
    "| **Weighting** | Counts word frequency | Considers word importance |\n",
    "| **Common Words** | High frequency | Lower weight |\n",
    "| **Rare Words** | Equal treatment | Higher weight |\n",
    "| **Meaningful Representation** | Less informative | More informative |\n",
    "\n",
    " **Conclusion**\n",
    "- **BoW is useful** when simple frequency-based features are needed, such as for basic text classification.\n",
    "- **TF-IDF is more effective** when identifying the most important words in a document, reducing the impact of common words and emphasizing unique terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End-to-end Sentiment Analysis Example in Python**\n",
    "\n",
    "To perform sentiment analysis using NLTK in Python, the text data must first be preprocessed using techniques such as tokenization, stop word removal, and stemming or lemmatization. Once the text has been preprocessed, we will then pass it to the **Vader sentiment analyzer** for analyzing the sentiment of the text (positive or negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Step 1 - Import libraries and load dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewText",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Positive",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2e213e60-83c4-4a91-99e9-56e9e98dd1b8",
       "rows": [
        [
         "0",
         "This is a one of the best apps acording to a bunch of people and I agree it has bombs eggs pigs TNT king pigs and realustic stuff",
         "1"
        ],
        [
         "1",
         "This is a pretty good version of the game for being free. There are LOTS of different levels to play. My kids enjoy it a lot too.",
         "1"
        ],
        [
         "2",
         "this is a really cool game. there are a bunch of levels and you can find golden eggs. super fun.",
         "1"
        ],
        [
         "3",
         "This is a silly game and can be frustrating, but lots of fun and definitely recommend just as a fun time.",
         "1"
        ],
        [
         "4",
         "This is a terrific game on any pad. Hrs of fun.  My grandkids love it. Great entertainment when waiting in long lines",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the amazon review dataset\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/amazon.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 - Preprocess text**\n",
    "\n",
    "Letâ€™s create a function preprocess_text in which we first tokenize the documents using word_tokenize function from NLTK, then we remove step words using stepwords module from NLTK and finally, we lemmatize the filtered_tokens using WordNetLemmatizer from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewText",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Positive",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7424c43b-0e92-4526-85d8-9d01c775359a",
       "rows": [
        [
         "0",
         "one best apps acording bunch people agree bomb egg pig tnt king pig realustic stuff",
         "1"
        ],
        [
         "1",
         "pretty good version game free . lot different level play . kid enjoy lot .",
         "1"
        ],
        [
         "2",
         "really cool game . bunch level find golden egg . super fun .",
         "1"
        ],
        [
         "3",
         "silly game frustrating , lot fun definitely recommend fun time .",
         "1"
        ],
        [
         "4",
         "terrific game pad . hr fun . grandkids love . great entertainment waiting long line",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free . lot different ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game . bunch level find golden egg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating , lot fun definitely re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad . hr fun . grandkids love . ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  one best apps acording bunch people agree bomb...         1\n",
       "1  pretty good version game free . lot different ...         1\n",
       "2  really cool game . bunch level find golden egg...         1\n",
       "3  silly game frustrating , lot fun definitely re...         1\n",
       "4  terrific game pad . hr fun . grandkids love . ...         1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create preprocess_text function\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenize the text\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "\n",
    "    # Join the tokens back into a string\n",
    "\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# apply the function df\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the changes in the \"review text\" column as a result of the preprocess_text function that we applied in the above step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 - NLTK Sentiment Analyzer**\n",
    "\n",
    "First, weâ€™ll initialize a **Sentiment Intensity Analyzer** object from the nltk.sentiment.vader library.\n",
    "\n",
    "Next, weâ€™ll define a function called get_sentiment that takes a text string as its input. The function calls the polarity_scores method of the analyzer object to obtain a dictionary of sentiment scores for the text, which includes a score for positive, negative, and neutral sentiment.\n",
    "\n",
    "The function will then check whether the positive score is greater than 0 and returns a sentiment score of 1 if it is, and a 0 otherwise. This means that any text with a positive score will be classified as having a positive sentiment, and any text with a non-positive score will be classified as having a negative sentiment.\n",
    "\n",
    "Finally, weâ€™ll apply the get_sentiment function to the reviewText column of the df DataFrame using the apply method. This creates a new column called sentiment in the DataFrame, which stores the sentiment score for each review. Weâ€™ll then display the updated DataFrame using df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewText",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Positive",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c799fd21-53ed-40b2-a883-8b538ad6e60f",
       "rows": [
        [
         "0",
         "one best apps acording bunch people agree bomb egg pig tnt king pig realustic stuff",
         "1",
         "1"
        ],
        [
         "1",
         "pretty good version game free . lot different level play . kid enjoy lot .",
         "1",
         "1"
        ],
        [
         "2",
         "really cool game . bunch level find golden egg . super fun .",
         "1",
         "1"
        ],
        [
         "3",
         "silly game frustrating , lot fun definitely recommend fun time .",
         "1",
         "1"
        ],
        [
         "4",
         "terrific game pad . hr fun . grandkids love . great entertainment waiting long line",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free . lot different ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game . bunch level find golden egg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating , lot fun definitely re...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad . hr fun . grandkids love . ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive  sentiment\n",
       "0  one best apps acording bunch people agree bomb...         1          1\n",
       "1  pretty good version game free . lot different ...         1          1\n",
       "2  really cool game . bunch level find golden egg...         1          1\n",
       "3  silly game frustrating , lot fun definitely re...         1          1\n",
       "4  terrific game pad . hr fun . grandkids love . ...         1          1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize NLTK sentiment analyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# create get_sentiment function\n",
    "\n",
    "def get_sentiment(text):\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply get_sentiment function\n",
    "\n",
    "df['sentiment'] = df['reviewText'].apply(get_sentiment)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK sentiment analyzer returns a score between -1 and +1. We have used a cut-off threshold of 0 in the get_sentiment function above. Anything above 0 is classified as 1 (meaning positive). Since we have actual labels, we can evaluate the performance of this method by building a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1131  3636]\n",
      " [  576 14657]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(df['Positive'], df['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.24      0.35      4767\n",
      "           1       0.80      0.96      0.87     15233\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.73      0.60      0.61     20000\n",
      "weighted avg       0.77      0.79      0.75     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df['Positive'], df['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the **overall accuracy of this rule-based sentiment analysis model is 79%.**\n",
    "\n",
    "Now, we will try to improve this with a ML-based approach. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewText",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Positive",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "87bf5acf-2456-4502-b73a-7ae7e5d6b714",
       "rows": [
        [
         "0",
         "one best apps acording bunch people agree bomb egg pig tnt king pig realustic stuff",
         "1",
         "1"
        ],
        [
         "1",
         "pretty good version game free . lot different level play . kid enjoy lot .",
         "1",
         "1"
        ],
        [
         "2",
         "really cool game . bunch level find golden egg . super fun .",
         "1",
         "1"
        ],
        [
         "3",
         "silly game frustrating , lot fun definitely recommend fun time .",
         "1",
         "1"
        ],
        [
         "4",
         "terrific game pad . hr fun . grandkids love . great entertainment waiting long line",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free . lot different ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game . bunch level find golden egg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating , lot fun definitely re...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad . hr fun . grandkids love . ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive  sentiment\n",
       "0  one best apps acording bunch people agree bomb...         1          1\n",
       "1  pretty good version game free . lot different ...         1          1\n",
       "2  really cool game . bunch level find golden egg...         1          1\n",
       "3  silly game frustrating , lot fun definitely re...         1          1\n",
       "4  terrific game pad . hr fun . grandkids love . ...         1          1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['reviewText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts:\n",
      " sentiment\n",
      "1    18293\n",
      "0     1707\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df['sentiment'].value_counts()\n",
    "print(\"Value counts:\\n\", value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_text'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train ML Model (Logistic Regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91825\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.07      0.12       341\n",
      "           1       0.92      1.00      0.96      3659\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.82      0.53      0.54      4000\n",
      "weighted avg       0.90      0.92      0.89      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall accuracy: 92%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**BERT SENTIMENT ANALYSIS**\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a powerful deep learning model for NLP tasks, including sentiment analysis. You can use transformers (Hugging Face) with a pre-trained BERT model to classify sentiment and compare it with SentimentIntensityAnalyzer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./bigdataenv/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./bigdataenv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./bigdataenv/lib/python3.12/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./bigdataenv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./bigdataenv/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./bigdataenv/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./bigdataenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./bigdataenv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./bigdataenv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./bigdataenv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./bigdataenv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./bigdataenv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./bigdataenv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets\n",
    "#jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./bigdataenv/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in ./bigdataenv/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in ./bigdataenv/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in ./bigdataenv/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./bigdataenv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./bigdataenv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./bigdataenv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./bigdataenv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./bigdataenv/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./bigdataenv/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./bigdataenv/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./bigdataenv/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./bigdataenv/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./bigdataenv/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./bigdataenv/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./bigdataenv/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./bigdataenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./bigdataenv/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in ./bigdataenv/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./bigdataenv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./bigdataenv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./bigdataenv/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./bigdataenv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./bigdataenv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./bigdataenv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./bigdataenv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./bigdataenv/lib/python3.12/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./bigdataenv/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bigdataenv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bigdataenv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bigdataenv/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bigdataenv/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./bigdataenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./bigdataenv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./bigdataenv/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./bigdataenv/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in ./bigdataenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in ./bigdataenv/lib/python3.12/site-packages (0.61.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./bigdataenv/lib/python3.12/site-packages (from numba) (0.44.0)\n",
      "Requirement already satisfied: numpy<2.2,>=1.24 in ./bigdataenv/lib/python3.12/site-packages (from numba) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cudatoolkit\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numba \n",
    "!pip install cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment  \u001b[38;5;66;03m# BERT sentiment labels: 0 (very negative) to 4 (very positive)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply BERT sentiment prediction\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_sentiment_bert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[72], line 15\u001b[0m, in \u001b[0;36mpredict_sentiment_bert\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     13\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m scores \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Convert logits to probabilities\u001b[39;00m\n\u001b[1;32m     17\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(scores)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Get highest probability class\u001b[39;00m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1673\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1673\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1685\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1687\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/pytorch_utils.py:261\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:640\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    554\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/spark/bigdataenv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"  # Can be changed to another sentiment model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to get sentiment prediction from BERT\n",
    "def predict_sentiment_bert(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    scores = F.softmax(output.logits, dim=1)  # Convert logits to probabilities\n",
    "    sentiment = torch.argmax(scores).item()  # Get highest probability class\n",
    "    return sentiment  # BERT sentiment labels: 0 (very negative) to 4 (very positive)\n",
    "\n",
    "\n",
    "# Apply BERT sentiment prediction\n",
    "df['bert_sentiment'] = df['clean_text'].apply(predict_sentiment_bert)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are discrete values from 1 to 5, where:\n",
    "1 = Very Negative ðŸ˜¡\n",
    "2 = Negative ðŸ˜ž\n",
    "3 = Neutral ðŸ˜\n",
    "4 = Positive ðŸ™‚\n",
    "5 = Very Positive ðŸ˜ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare BERT with VADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    text  bert_sentiment  vader_sentiment\n",
      "0   I love this product!               4                1\n",
      "1      This is terrible.               0                0\n",
      "2  Absolutely fantastic!               4                1\n",
      "3             I hate it.               0                0\n",
      "4        Meh, it's okay.               2                1\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get VADER sentiment scores\n",
    "df['vader_score'] = df['text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "df['vader_sentiment'] = df['vader_score'].apply(lambda x: 1 if x >= 0 else 0)  # 1 = Positive, 0 = Negative\n",
    "\n",
    "# Compare Results\n",
    "print(df[['text', 'bert_sentiment', 'vader_sentiment']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Evaluate Accuracy?**\n",
    "\n",
    "If you have labeled sentiment data (e.g., df['true_sentiment']), you can compare both models using accuracy_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Accuracy: 1.00\n",
      "BERT Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume we have true sentiment labels (1 = Positive, 0 = Negative)\n",
    "df['true_sentiment'] = [1, 0, 1, 0, 1]\n",
    "\n",
    "# Compute Accuracy\n",
    "vader_acc = accuracy_score(df['true_sentiment'], df['vader_sentiment'])\n",
    "bert_acc = accuracy_score(df['true_sentiment'], df['bert_sentiment'])\n",
    "\n",
    "print(f\"VADER Accuracy: {vader_acc:.2f}\")\n",
    "print(f\"BERT Accuracy: {bert_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ **Conclusion**\n",
    "\n",
    "- VADER is rule-based and fast but may struggle with complex sentences.\n",
    "- BERT is deep-learning based and generally provides better accuracy for sentiment analysis.\n",
    "- Compare both on a larger dataset to make a final decision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdataenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}